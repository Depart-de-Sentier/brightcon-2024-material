{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, defining the decorator, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from marquez_client import MarquezClient\n",
    "from marquez_client.models import JobType\n",
    "import os\n",
    "from openlineage.client import OpenLineageClient\n",
    "from openlineage.client.transport.file import FileConfig, FileTransport\n",
    "from openlineage.client.transport.http import HttpConfig, HttpCompression, HttpTransport\n",
    "from openlineage.client.event_v2 import RunEvent, RunState, Run, Job, Dataset, DatasetEvent, JobEvent\n",
    "from openlineage.client.uuid import generate_new_uuid\n",
    "from datetime import datetime\n",
    "from openlineage.client.facet import NominalTimeRunFacet\n",
    "import logging\n",
    "from functools import wraps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import re\n",
    "import brightway2 as bw\n",
    "import bw2data as bd\n",
    "import bw2io as bi\n",
    "# import bw2calc as bc\n",
    "# import bw2analyzer as bwa\n",
    "import inspect\n",
    "import getpass\n",
    "from openlineage.client.uuid import generate_new_uuid\n",
    "import json\n",
    "import hashlib\n",
    "from openlineage.client.facet import  SqlJobFacet, SchemaDatasetFacet, SchemaField, OutputStatisticsOutputDatasetFacet,SourceCodeLocationJobFacet, NominalTimeRunFacet,DataQualityMetricsInputDatasetFacet,ColumnMetric\n",
    "# from openlineage.client import ZonedDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_hash(data):\n",
    "    return hashlib.sha256(data.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output_dataset_name = None\n",
    "last_output_dataset_hash = None\n",
    "seen_datasets = {} ### dict with names and hashes as values\n",
    "os.environ['OPENLINEAGE_CONFIG'] = 'openlineage.yml'  \n",
    "\n",
    "def log_job_2(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "\n",
    "        if not args and not kwargs:\n",
    "            return func\n",
    "            \n",
    "        namespace = 'trial_1'\n",
    "        transport_type = \"http\"\n",
    "        PRODUCER = f\"https://github.com/openlineage-user\"\n",
    "\n",
    "        if transport_type == \"file\":\n",
    "            file_config = FileConfig(\n",
    "                log_file_path=\"test-lineage-file\",\n",
    "                append=True,\n",
    "            )\n",
    "            client = OpenLineageClient(transport=FileTransport(file_config))\n",
    "        elif transport_type == \"http\":\n",
    "            http_config = HttpConfig(\n",
    "                url=\"http://localhost:5000\",\n",
    "                endpoint=\"api/v1/lineage\",\n",
    "                timeout=5,\n",
    "                verify=False,\n",
    "                # auth=ApiKeyTokenProvider({\"apiKey\": \"f048521b-dfe8-47cd-9c65-0cb07d57591e\"}),\n",
    "                compression=HttpCompression.GZIP,\n",
    "            )\n",
    "            client = OpenLineageClient(transport=HttpTransport(http_config))\n",
    "        elif transport_type == \"console\":\n",
    "            # See https://openlineage.io/docs/client/python#console\n",
    "            console_config = ConsoleConfig()\n",
    "            client = OpenLineageClient(transport=ConsoleTransport(console_config))\n",
    "\n",
    "\n",
    "        description = func.__doc__\n",
    "        func_name = func.__name__\n",
    "        executor = getpass.getuser() ### will this surely run on other systems?\n",
    "\n",
    "\n",
    "        global last_output_dataset_name, last_output_dataset_hash\n",
    "        global last_params\n",
    "        sig = inspect.signature(func)\n",
    "        bound_args = sig.bind(*args, **kwargs)\n",
    "        bound_args.apply_defaults()\n",
    "\n",
    "        last_params = bound_args.arguments  ### Store the last parameters\n",
    "        ### Define the job (same for all function executions)\n",
    "        job = Job(namespace= namespace, name= str(generate_new_uuid()))\n",
    "        runId = str(generate_new_uuid())\n",
    "        run = Run(\n",
    "            runId=runId,\n",
    "            facets={\n",
    "                \"transformation_description\": description, #BaseFacet(description=description)\n",
    "                'name' : func_name,\n",
    "                'executed by': executor,\n",
    "                'arguments': last_params,\n",
    "                #'facets':{\"nominalTime\": NominalTimeRunFacet(getNominalStartTime())}\n",
    "            } )\n",
    "        \n",
    "\n",
    "        if args:\n",
    "            input_data = args[0] \n",
    "            output_data = func(*args, **kwargs)\n",
    "\n",
    "        else:\n",
    "            input_data = None \n",
    "            output_data = func(**kwargs)\n",
    "\n",
    "        input_data_serialized = str(input_data) \n",
    "        output_data_serialized = str(output_data)\n",
    "\n",
    "\n",
    "        input_hash = generate_dataset_hash(input_data_serialized)\n",
    "        output_hash = generate_dataset_hash(output_data_serialized)\n",
    "        # input_name = list(bound_args.arguments.keys())[0] if args else None\n",
    "\n",
    "        input_name = f\"{input_data=}\".split('=')[0]\n",
    "        output_name = 'output' + runId #f\"{output_data=}\".split('=')[0]\n",
    "        seen_datasets[output_hash] = output_name\n",
    "\n",
    "        if input_hash in seen_datasets.keys():\n",
    "            input_dataset_name = seen_datasets[input_hash]\n",
    "        else:\n",
    "            input_dataset_name = input_name  \n",
    "\n",
    "        input_dataset = Dataset(\n",
    "            namespace=namespace,\n",
    "            name=input_dataset_name,\n",
    "            facets={\"dataHash\": {\n",
    "            \"type\": \"CustomFacet\",  # Custom facet for dataset hash\n",
    "            \"hash\": input_hash},  # Hash of the input dataset content\n",
    "            'type' : type(input_data),\n",
    "            #'schema' : schema\n",
    "            })\n",
    "        output_dataset = Dataset(\n",
    "            namespace=namespace,\n",
    "            name=output_name,\n",
    "           facets={\"dataHash\": {\n",
    "            \"type\": \"CustomFacet\",  \n",
    "            \"hash\": output_hash},  \n",
    "            'type' : type(output_data), })\n",
    "            #\"_producer\": \"https://github.com/OpenLineage/OpenLineage/blob/v1-0-0/client\",\n",
    "            #\"_schemaURL\": \"https://github.com/OpenLineage/OpenLineage/blob/v1-0-0/spec/OpenLineage.json#/definitions/SchemaDatasetFacet\"})\n",
    "\n",
    "        client.emit(\n",
    "            RunEvent(\n",
    "                eventType=RunState.COMPLETE,\n",
    "                eventTime=datetime.now().isoformat(),\n",
    "                run=run,\n",
    "                job=job,\n",
    "                inputs=[input_dataset],\n",
    "                outputs=[output_dataset]\n",
    "            )    )\n",
    "\n",
    "        return output_data\n",
    "        wrapper.__name__ = func.__name__ + \"_decorated\" ### to keep the name of the function as is\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example (Decorated User-Defined Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('technosphere exchanges description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_job_2\n",
    "def times_two(input = 154):\n",
    "    '''multiplies the input by 2'''\n",
    "    output = input * 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = times_two(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_job_2\n",
    "def first_forward(input):\n",
    "    '''removes the first column'''\n",
    "    if type(input) == pd.core.frame.DataFrame:\n",
    "        output = input.iloc[:, 1:].copy()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = first_forward(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_job_2\n",
    "def transposer(input):\n",
    "    '''transposes the matrix'''\n",
    "    if type(input) == pd.core.frame.DataFrame:\n",
    "        output = input.T\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = transposer(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = times_two(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecoinvent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bw2io' from 'c:\\\\miniconda\\\\envs\\\\brightcon\\\\Lib\\\\site-packages\\\\bw2io\\\\__init__.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(bi) ### in case you want to have a fresh start for bw2io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### i have commented the last bit to ensure the recursion error doesnt happen (spoiler alert: it still does)\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "def apply_logging_to_package(package, decorator):\n",
    " \n",
    "     for name, obj in inspect.getmembers(package):\n",
    "\n",
    "        if inspect.isfunction(obj):\n",
    "            #print('well, hello there!')\n",
    "            setattr(package, name, decorator(obj))\n",
    "\n",
    "        elif inspect.isclass(obj):\n",
    "            for method_name, method in inspect.getmembers(obj, predicate=inspect.isfunction):\n",
    "\n",
    "                setattr(obj, method_name, decorator(method))\n",
    "\n",
    "        # elif inspect.ismodule(obj):\n",
    "        #     for method_name, method in inspect.getmembers(obj, predicate=inspect.isfunction):\n",
    "\n",
    "        #         setattr(obj, method_name, decorator(method))\n",
    "\n",
    "apply_logging_to_package(bi, log_job_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring project backup archive - this could take a few minutes...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hack-a-fun!!!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This is just the biosphere, but perhaps itd be better to also circle back to it\n",
    "\n",
    "bi.remote.install_project(\n",
    "    project_name=\"hack-a-fun!!!\",\n",
    "    project_key=\"ecoinvent-3.10-biosphere\", \n",
    "    projects_config={\"ecoinvent-3.10-biosphere\": \"ecoinvent-3.10-biosphere.bw2.tar.gz\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw.projects.set_current('hack-a-fun!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 1 object(s):\n",
       "\tecoinvent-3.10-biosphere"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw.databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__ ### make sure its not 2.0 as theres currently incompatibility issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ecospold2 files:\n",
      "0% [##############################] 100% | ETA: 00:00:00 | Item ID: ffaf660d-37cc-5\n",
      "Total time elapsed: 00:00:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Extracting ecospold2 files:\n",
      "  Started: 09/27/2024 11:28:40\n",
      "  Finished: 09/27/2024 11:29:07\n",
      "  Total time elapsed: 00:00:27\n",
      "  CPU %: 85.20\n",
      "  Memory %: 4.52\n",
      "Extracted 2905 datasets in 27.21 seconds\n"
     ]
    }
   ],
   "source": [
    "db_path = '/Users/Farhang Raymand/Downloads/ecoinvent_test' #ecoinvent 3.10_cutoff_ecoSpold02/datasets'      ### Takes 10.5 minutes\n",
    "db_name = 'ecoinvent 3.10 cutoff -  lineage'\n",
    "\n",
    "if 'ecoinvent 3.10 small -  lineage' in bw.databases:\n",
    "    print(\"Database has already been imported\")\n",
    "else:\n",
    "    ei = bi.SingleOutputEcospold2Importer(db_path, db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying strategy: normalize_units\n",
      "Applying strategy: update_ecoinvent_locations\n",
      "Applying strategy: remove_zero_amount_coproducts\n",
      "Applying strategy: remove_zero_amount_inputs_with_no_activity\n",
      "Applying strategy: remove_unnamed_parameters\n",
      "Applying strategy: es2_assign_only_product_with_amount_as_reference_product\n",
      "Applying strategy: assign_single_product_as_activity\n",
      "Applying strategy: create_composite_code\n",
      "Applying strategy: drop_unspecified_subcategories\n",
      "Applying strategy: fix_ecoinvent_flows_pre35\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ei\u001b[38;5;241m.\u001b[39mapply_strategies() \n\u001b[0;32m      2\u001b[0m ei\u001b[38;5;241m.\u001b[39mstatistics()\n\u001b[0;32m      3\u001b[0m ei\u001b[38;5;241m.\u001b[39mwrite_database()\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "File \u001b[1;32mc:\\miniconda\\envs\\brightcon\\Lib\\site-packages\\bw2io\\importers\\base.py:69\u001b[0m, in \u001b[0;36mImportBase.apply_strategies\u001b[1;34m(self, strategies, verbose)\u001b[0m\n\u001b[0;32m     67\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(func_list)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(func_list):\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_strategy(func, verbose)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39memit(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, total)\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "File \u001b[1;32mc:\\miniconda\\envs\\brightcon\\Lib\\site-packages\\bw2io\\importers\\base.py:48\u001b[0m, in \u001b[0;36mImportBase.apply_strategy\u001b[1;34m(self, strategy, verbose)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying strategy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(func_name))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m strategy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplied_strategies\u001b[38;5;241m.\u001b[39mappend(func_name)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StrategyError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\miniconda\\envs\\brightcon\\Lib\\site-packages\\bw2io\\strategies\\ecospold2.py:1068\u001b[0m, in \u001b[0;36mfix_ecoinvent_flows_pre35\u001b[1;34m(db)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;124;03mApply the 'fix-ecoinvent-flows-pre-35' migration to the given database if\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;124;03mavailable; otherwise, raise a warning and return the unmodified database.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;124;03m]\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfix-ecoinvent-flows-pre-35\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m migrations:\n\u001b[1;32m-> 1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m migrate_exchanges(db, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfix-ecoinvent-flows-pre-35\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1070\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1071\u001b[0m         (\n\u001b[0;32m   1072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping migration \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfix-ecoinvent-flows-pre-35\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1073\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause it isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1074\u001b[0m         )\n\u001b[0;32m   1075\u001b[0m     )\n",
      "File \u001b[1;32mc:\\miniconda\\envs\\brightcon\\Lib\\site-packages\\bw2io\\strategies\\migrations.py:34\u001b[0m, in \u001b[0;36mmigrate_exchanges\u001b[1;34m(db, migration)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmigrate_exchanges\u001b[39m(db, migration):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m migration \u001b[38;5;129;01min\u001b[39;00m migrations, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find migration \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(migration)\n\u001b[1;32m---> 34\u001b[0m     migration_data \u001b[38;5;241m=\u001b[39m Migration(migration)\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     36\u001b[0m     to_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(migration_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m\"\u001b[39m], x))\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Create dict of lookup fields to new data. There shouldn't be\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# duplicates for the lookup fields, as they will be overwritten\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# during mapping creation.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "Cell \u001b[1;32mIn[19], line 73\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[0;32m     71\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 73\u001b[0m input_data_serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_data) \n\u001b[0;32m     74\u001b[0m output_data_serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(output_data)\n\u001b[0;32m     77\u001b[0m input_hash \u001b[38;5;241m=\u001b[39m generate_dataset_hash(input_data_serialized)\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "Cell \u001b[1;32mIn[19], line 73\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[0;32m     71\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 73\u001b[0m input_data_serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_data) \n\u001b[0;32m     74\u001b[0m output_data_serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(output_data)\n\u001b[0;32m     77\u001b[0m input_hash \u001b[38;5;241m=\u001b[39m generate_dataset_hash(input_data_serialized)\n",
      "    \u001b[1;31m[... skipping similar frames: log_job_2.<locals>.wrapper at line 67 (989 times), log_job_2.<locals>.wrapper at line 73 (989 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[19], line 67\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m     66\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m---> 67\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "Cell \u001b[1;32mIn[19], line 73\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[0;32m     71\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 73\u001b[0m input_data_serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(input_data) \n\u001b[0;32m     74\u001b[0m output_data_serialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(output_data)\n\u001b[0;32m     77\u001b[0m input_hash \u001b[38;5;241m=\u001b[39m generate_dataset_hash(input_data_serialized)\n",
      "Cell \u001b[1;32mIn[19], line 24\u001b[0m, in \u001b[0;36mlog_job_2.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenLineageClient(transport\u001b[38;5;241m=\u001b[39mFileTransport(file_config))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m transport_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 24\u001b[0m     http_config \u001b[38;5;241m=\u001b[39m HttpConfig(\n\u001b[0;32m     25\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:5000\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi/v1/lineage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     28\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# auth=ApiKeyTokenProvider({\"apiKey\": \"f048521b-dfe8-47cd-9c65-0cb07d57591e\"}),\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         compression\u001b[38;5;241m=\u001b[39mHttpCompression\u001b[38;5;241m.\u001b[39mGZIP,\n\u001b[0;32m     31\u001b[0m     )\n\u001b[0;32m     32\u001b[0m     client \u001b[38;5;241m=\u001b[39m OpenLineageClient(transport\u001b[38;5;241m=\u001b[39mHttpTransport(http_config))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m transport_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# See https://openlineage.io/docs/client/python#console\u001b[39;00m\n",
      "File \u001b[1;32m<attrs generated init openlineage.client.transport.http.HttpConfig>:9\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, url, endpoint, timeout, verify, auth, compression, session, adapter)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauth \u001b[38;5;241m=\u001b[39m auth\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauth \u001b[38;5;241m=\u001b[39m __attr_factory_auth()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m session\n",
      "File \u001b[1;32mc:\\miniconda\\envs\\brightcon\\Lib\\site-packages\\openlineage\\client\\transport\\http.py:84\u001b[0m, in \u001b[0;36mHttpConfig.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# check TLS certificates\u001b[39;00m\n\u001b[0;32m     83\u001b[0m verify: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mib(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 84\u001b[0m auth: TokenProvider \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mib(factory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: TokenProvider({}))\n\u001b[0;32m     85\u001b[0m compression: HttpCompression \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mib(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# not set by TransportFactory\u001b[39;00m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "ei.apply_strategies() \n",
    "ei.statistics()\n",
    "ei.write_database()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brightcon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
